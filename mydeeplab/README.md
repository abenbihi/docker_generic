## Building Deeplab caffe
Build only 

    # Build 
    make build

Build and run 
    
    # Set the external volume you want to mount
    EXTERNAL_PATH_TO_WS=external_volume

    # Set the internal volume you want to mount
    LOCAL_PATH_TO_WS=internal_volume

    # Build and run 
    make root

## Training deeplab

### Download the running script and the dataset

The scripts used for training and post-processing can be downloaded from this [link](https://ucla.app.box.com/s/4grlj8yoodv95936uybukjh5m0tdzvrf) :
	
	# the script for training/testing on the PASCAL VOC 2012 dataset. Note You also need to download sub.sed script.
    run_pascal.sh
	# the scripts we used for post-processing the DCNN computed results by DenseCRF.
	run_densecrf.sh 
	run_densecrf_grid_search.sh

The image list files used in our experiments can be downloaded from this [link](https://ucla.app.box.com/s/rd9z2xvwsfpksi7mi08i2xqrj7ab4keb):

The datasets can be found at these links:
- [Augmented PASCAL VOC: VOC_aug](http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/semantic_contours/benchmark.tgz) 1.3 GB
- [original PASCAL VOC 2012: VOC2012_orig](http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar) 2GB

### Data conversion
Let $DATASETS be the directory holding your dataset.
Download the conversion scripts 'mat2png.py' and 'convert_labels.py' from this [link](https://github.com/martinkersner/train-DeepLab)

Unfortunately, ground truth labels within augmented PASCAL VOC dataset are distributed as Matlab data files, therefore we will have to convert them before we can start training itself.

	cd $DATASETS/VOC_aug/dataset
	mkdir cls_png
	cd $DEEPLAB
	./mat2png.py $DATASETS/VOC_aug/dataset/cls $DATASETS/VOC_aug/dataset/cls_png

Caffe softmax loss function can accept only one-channel ground truth labels. However, those labels in original PASCAL VOC 2012 dataset are defined as RGB images. Thus, we have to reduce their dimensionality.

	cd $DATASETS/VOC2012_orig
	mkdir SegmentationClass_1D

	./convert_labels.py $DATASETS/VOC2012_orig/SegmentationClass/ \
	  $DATASETS/VOC2012_orig/ImageSets/Segmentation/trainval.txt \
	  $DATASETS/VOC2012_orig/SegmentationClass_1D/

At last, part of code which computes DenseCRF is able to work only with PPM image files, hence we have to perform another conversion. This step is necessary only if we want to use DenseCRF separately and as one of Caffe layers.

    # DO NOT USE ANY OTHER CODE TO DO THE CONVERSION !!!! 
    # the crf script accepts only the ppm images generated with this code.
    # Don't ask why.
	  # Modify the path variables and run the following script in matlab:
    deeplab/code/densecrf/my_script/SaveJpgToPPM.m

### Workspace creation

    WS_DIR = /opt/BenbihiAssia/deeplab/
    cd $WS_DIR
    mkdir datasets
    mkdir exper

Dataset directory 

    cd datasets
    mkdir <dataset name>
    cd <dataset name>
    # place everything related to this dataset here
    # this should contain
    #   - train_rgb
    #   - train_label
    #   - val_rgb
    #   - val label

Exper directory

    cd exper
    ./create_dir.sh <xp name>

You should have files with the name of the images for train and test. Copy
them:

    cp train.txt <xp name>/list/
    cp val.txt <xp name>/list/

Generate the image ids from val.txt. This file 'val\_id.txt' should contain
only the image id and the image filename

    python3 val2valid.py <xp name>/list/val.txt <xp name>/list/val_id.txt

Copy the network model into config

    cp *.prototxt <xp name>/resnet/config
    cp *.caffemodel <xp name>/resnet/config #from which you finetune

### Training

    # solver_train.prototxt has been generated by run+pascal.sh from the solver template. 
    # It also generates train_train.prototxt from train.prototxt 
    # and test_train.prototxt from test.prototxt

    cd exper
    caffe train --solver=antoine/config/resnet/solver_train.prototxt --weights=antoine/config/resnet/train_iter_20000.caffemodel

### Generate features map to feed crf: this creates fcn8 in deeplab/exper/voc12/features/deep_largeFOV/val/fc8
    # feature map in .mat format
    # Assuming you have generated test_val.prototxt with run_pascal.sh 
    
    cd exper
    caffe test --model=voc12/config/deep_largeFOV/test_val.prototxt --weights=voc12/config/deep_largeFOV/train_iter_20000.caffemodel --gpu=0 --iterations=1449
    
    # The code freezes on the output line "Running 1449 iterations": it is
    normal. It is computing the feature maps on the 1449 images.
    # You can kill it once you see "data layer prefetch queue empty ..."

### Set crf 

This assumes that you also have the PPI images on the supelec gpu.

The densecrf/Makefile uploaded by the docker with the deeplab-ver2 repository lacks a link. 
So the best strategy for now is to compile it by hand once you run the docker

    # Add the missing link to libhfd5 after -lmatio
    # To build prog_refine_pascal_v4
    # In the docker image
    
    cd code/densecrf
    vim Makefile
    $(CC) refine_pascal_v4/dense_inference.cpp -o prog_refine_pascal_v4 $(CFLAGS) -L. -lDenseCRF -lmatio -lhdf5 -I./util/

    # If you image dataset is seperated into several subdirectories
    # Modify the code to read the image name from the feature maps
    # For Antoine Richard (stage classif ortho image) structure, add this code in the refine_pascal_v4 main loop after for (size_t i = 0; i < feat_file_names.size(); ++i) {
    
    std::string fn;
    std::string subdir;
    std::cout << "img_filenames[i]" << img_file_names[i] <<  std::endl;
    std::cout << img_file_names[i].size() << std::endl;
    if(img_file_names[i].size()<4){
      fn = std::string(inp.ImgDir) + "/0/" + img_file_names[i] + ".ppm";
      std::cout << "[0] " << std::string(inp.ImgDir) << "/0/" << img_file_names[i] <<  std::endl;
      std::cout << "[0] img_filename: " << fn << std::endl;
    }
    else if(img_file_names[i].size()==4){
      subdir = img_file_names[i].substr(0,1) + "/" ;
      //int j=1;
      //const char* str_tmp = &img_file_names[i][j];
      //while(::strcmp(str_tmp,"0")==0){
      //  j++;
      //}
      //img_filename = img_file_names[i].substr(j, std::string::npos);
      fn = std::string(inp.ImgDir) + "/" + subdir + img_file_names[i] + ".ppm";
      std::cout << "subdir: " << subdir << std::endl;
      std::cout << "img_filename: " << fn << std::endl;
    }
    else if(img_file_names[i].size()==5){
      subdir = img_file_names[i].substr(0,2) + "/" ;
      fn = std::string(inp.ImgDir) + "/" + subdir + img_file_names[i] + ".ppm";
      std::cout << "subdir: " << subdir << std::endl;
      std::cout << "img_filename: " << fn << std::endl;
    }

    ## If you have a segfault, check that your feature maps have the correct pattern
    ## In the main file, it is the variable strip_pattern.
    By default, it is 'blob_0' but you may have 'blob_1' or another

### Post process your feature maps using crf (... it is long)
 
    # This process your features maps with crf and save the segmentation result
    # into a binary file
    
    cd exper
    ./run_densecrf.sh

### Visualize your results
    # In matlab
    /home/gpu_user/assia/ws/tf/deeplab/code/densecrf/my_script/GetDenseCRFResult.m

## Generic README.md 

### Set the caffe path in your docker image
    
    export PYTHONPATH=$PYTHONPATH:/opt/caffe/python

### Launch the image (assumed you have built the image)
--volume=external\_path:local\_path mounts external\_path in local\_path in the image
    
    nvidia-docker run --volume=/opt/BenbihiAssia/deeplab/:/home/ws -it -u root deeplab bash

### Caffe useful commands 

Finetuning: 
    
    caffe train -solver solver.prototxt -weights ../fcn8s-heavy-pascal.caffemodel

